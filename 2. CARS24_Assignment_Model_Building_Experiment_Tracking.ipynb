{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43101d05-0530-43c2-bc80-c4cc9d0ab26c",
   "metadata": {},
   "source": [
    "# Cars24 : MLOps/Platform Engineer Position : Assignment : Train a model on MNIST handwritten digit dataset. \n",
    "\n",
    "# Candidate : ***Tanmaya Chaudhary***\n",
    "\n",
    "# Outline\n",
    "- [ 1 - Objective ](#1)\n",
    "- [ 2 - Packages ](#2)\n",
    "- [ 3 - Import The MNIST Dataset](#3)\n",
    "- [ 4 - Data Preprocessing](#4)\n",
    "- [ 5 - Performance Evaluation & Tracking Functions](#5)\n",
    "- [ 6 - Experiment Creation in MLflow for Tracking.](#6)\n",
    "- [ 7 - Machine Learning Model Building : ](#7)\n",
    "  - [ 7.1 Multi-class Logistic Regression](#7.1)\n",
    "  - [ 7.2 Random Forest](#7.2)\n",
    "  - [ 7.3 Multi Layer Perceptron (MLP)](#7.3)\n",
    "  - [ 7.4 Normal Neural Network](#7.4)\n",
    "- [ 8 - Run MLflow tracking UI](#8)\n",
    "- [ 9 - Get The Best Model Based on Accuracy](#9)\n",
    "- [ 10 - Inferencing Using 1st Image of Training Set](#10)\n",
    "- [ 11 - Save the best model i.e. Neural Network Model into a folder Best_Model for Inference & Deployment.](#11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7249fcd9-a605-427e-b85e-4957ff31404c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"1\"></a>\n",
    "## 1 - Objective \n",
    "\n",
    "### We will experiment with MNIST dataset using multiple learning algorithms like Logistic Regression, Random Forest, Multi Layer Perceptron, Normal Neural Network.\n",
    "\n",
    "### We are given 28 X 28 pixels of handwritten digits, we have to predict the numbers from 0 to 9.\n",
    "\n",
    "### It's a multi-class classification problem as we there are 10 classes from 0 to 9.\n",
    "\n",
    "### 6 Evaluation Metrics are considered:\n",
    "- Accuracy.\n",
    "- Precision.\n",
    "- Recall.\n",
    "- F1-Score.\n",
    "- Training Time.\n",
    "- Prediction Time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e839c32-8ef8-4e78-9c5c-5ada6e48793d",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## 2 - Packages \n",
    "\n",
    "First, let's run the cell below to import all the packages that we will need during this assignment.\n",
    "- [numpy](https://numpy.org/) is the fundamental package for scientific computing with Python.\n",
    "- [matplotlib](http://matplotlib.org) is a popular library to plot graphs in Python.\n",
    "- [tensorflow](https://www.tensorflow.org/) a popular platform for machine learning.\n",
    "- [pandas](https://pandas.pydata.org/) is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language.\n",
    "- [mlflow](https://mlflow.org/docs/latest/index.html) is a module provides a high-level “fluent” API for starting and managing MLflow runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "208ebe86-bd79-4794-993a-a15af478ab80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Packages.\n",
    "\n",
    "# Numeric Calculations & Data Manuplation.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.models   import Sequential\n",
    "from tensorflow.keras.layers   import Dense , Conv2D , MaxPooling2D, Flatten\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Models.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble     import RandomForestClassifier\n",
    "\n",
    "# Performance Evaluation.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics         import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Experiment Tracking.\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "import mlflow.sklearn\n",
    "import mlflow.keras\n",
    "#import mlflow.tensorflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Visualization.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Others\n",
    "import random\n",
    "import time\n",
    "\n",
    "# # For Model Registration.: Use only after MySQL or any Storage is configured for Model Registry.\n",
    "# import MySQLdb\n",
    "import os\n",
    "#os.environ['MLFLOW_TRACKING_URI'] = 'mysql+mysqldb://root:root@localhost:3306/mlflow'\n",
    "\n",
    "os.environ['MLFLOW_TRACKING_URI'] = 'http://127.0.0.1:5000'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4955aa3-ff7c-40bc-830e-f7cfb79b1784",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"3\"></a>\n",
    "## 3 - Import The MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a49310b-be52-4651-b9dd-8ad388d5e995",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28), (60000,), (10000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dataaset could be downloaded using Keras API\n",
    "# It consists 28x28 greyscale images of 10 digits, 60k samples for training set, and 10k samples for test set.\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data(path='mnist.npz')\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a7d4939-d2d5-48f3-9f0a-9d6a08ee8323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set : \n",
      "Number of samples per class [0 to 9] : \n",
      "Class : 0     No. of Samples : 5923\n",
      "Class : 1     No. of Samples : 6742\n",
      "Class : 2     No. of Samples : 5958\n",
      "Class : 3     No. of Samples : 6131\n",
      "Class : 4     No. of Samples : 5842\n",
      "Class : 5     No. of Samples : 5421\n",
      "Class : 6     No. of Samples : 5918\n",
      "Class : 7     No. of Samples : 6265\n",
      "Class : 8     No. of Samples : 5851\n",
      "Class : 9     No. of Samples : 5949\n",
      "\n",
      "Proportion of each class [0 to 9] : \n",
      "Class : 0     Proportion : 0.099\n",
      "Class : 1     Proportion : 0.112\n",
      "Class : 2     Proportion : 0.099\n",
      "Class : 3     Proportion : 0.102\n",
      "Class : 4     Proportion : 0.097\n",
      "Class : 5     Proportion : 0.09\n",
      "Class : 6     Proportion : 0.099\n",
      "Class : 7     Proportion : 0.104\n",
      "Class : 8     Proportion : 0.098\n",
      "Class : 9     Proportion : 0.099\n",
      "\n",
      "\n",
      "Test Set : \n",
      "Number of samples per class [0 to 9] : \n",
      "Class : 0     No. of Samples : 980\n",
      "Class : 1     No. of Samples : 1135\n",
      "Class : 2     No. of Samples : 1032\n",
      "Class : 3     No. of Samples : 1010\n",
      "Class : 4     No. of Samples : 982\n",
      "Class : 5     No. of Samples : 892\n",
      "Class : 6     No. of Samples : 958\n",
      "Class : 7     No. of Samples : 1028\n",
      "Class : 8     No. of Samples : 974\n",
      "Class : 9     No. of Samples : 1009\n",
      "\n",
      "Proportion of each class [0 to 9] : \n",
      "Class : 0     Proportion : 0.098\n",
      "Class : 1     Proportion : 0.114\n",
      "Class : 2     Proportion : 0.103\n",
      "Class : 3     Proportion : 0.101\n",
      "Class : 4     Proportion : 0.098\n",
      "Class : 5     Proportion : 0.089\n",
      "Class : 6     Proportion : 0.096\n",
      "Class : 7     Proportion : 0.103\n",
      "Class : 8     Proportion : 0.097\n",
      "Class : 9     Proportion : 0.101\n"
     ]
    }
   ],
   "source": [
    "# Number of samples for each class in training set.\n",
    "unique, count = np.unique(y_train, return_counts=True)\n",
    "\n",
    "print(\"Training Set : \")\n",
    "\n",
    "# Number of samples per class.\n",
    "num_samples = dict(zip(unique, count))\n",
    "print(\"Number of samples per class [0 to 9] : \")\n",
    "for class_name, samples in num_samples.items():\n",
    "    print(f\"Class : {class_name}     No. of Samples : {samples}\")\n",
    "\n",
    "# Proportion of each class.\n",
    "print(\"\\nProportion of each class [0 to 9] : \")\n",
    "proportion_of_each_class = dict(zip(unique, np.round(count / count.sum(),3)))\n",
    "for class_name, proportion in proportion_of_each_class.items():\n",
    "    print(f\"Class : {class_name}     Proportion : {proportion}\")\n",
    "    \n",
    "\n",
    "print(\"\\n\\nTest Set : \")    \n",
    "\n",
    "# Number of samples for each class.\n",
    "unique, count = np.unique(y_test, return_counts=True)\n",
    "num_samples = dict(zip(unique, count))\n",
    "print(\"Number of samples per class [0 to 9] : \")\n",
    "for class_name, samples in num_samples.items():\n",
    "    print(f\"Class : {class_name}     No. of Samples : {samples}\")\n",
    "\n",
    "# Proportion of each class.\n",
    "print(\"\\nProportion of each class [0 to 9] : \")\n",
    "proportion_of_each_class = dict(zip(unique, np.round(count / count.sum(),3)))\n",
    "for class_name, proportion in proportion_of_each_class.items():\n",
    "    print(f\"Class : {class_name}     Proportion : {proportion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e96b466-0c54-4db5-91c2-15083dc027bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n",
      "Shape: (28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fbd5208308>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check one of the image.\n",
    "\n",
    "n = random.randint(0,59999)\n",
    "\n",
    "print(\"Label: %s\" % (y_train[n])),\n",
    "print(\"Shape: %s\" % (str(X_train[n].shape))),\n",
    "plt.imshow(X_train[n,:], interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350a6080-4bf1-447f-a750-122a2e222f60",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "## 4 - Data Preprocessing\n",
    "In this section, we will:\n",
    "1. Create two types of features space: flatten and as-is.\n",
    "2. Normalize the value previously ranging from 0-255 to 0-1 to fasten the convergence time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "815af798-960b-4e5c-808d-6006b2b5acbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examlple value on pixels before normalization : [  0   0   0  46 245 163   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0 198 254  56   0   0   0   0   0   0]\n",
      "Examlple value on pixels after normalization : [0.         0.         0.         0.18039216 0.96078431 0.63921569\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.77647059 0.99607843 0.21960784 0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Normalize the data.\n",
    "\n",
    "# Before Normalization.\n",
    "print(f\"Examlple value on pixels before normalization : {X_train[2,10,:]}\") # the higher the darker\n",
    "\n",
    "# Normalization.\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# pAfter Normalization.\n",
    "print(f\"Examlple value on pixels after normalization : {X_train[2,10,:]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6580889d-f5c2-4a94-b7ca-c0a999b2bb7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000, 28, 28, 1), (10000, 784), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create flatten feature space.\n",
    "\n",
    "# Reshape from 28x28 to 784.\n",
    "X_train_flat = X_train.reshape(-1,784) \n",
    "X_test_flat = X_test.reshape(-1, 784)\n",
    "\n",
    "# Reshape the 28x28 to 28x28x1 for input CNN\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Check the final shape.\n",
    "X_train_flat.shape, X_train.shape, X_test_flat.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954a9fd4-2420-460f-aa6e-9cbaee31e7e3",
   "metadata": {},
   "source": [
    "<a name=\"5\"></a>\n",
    "## 5 - Performance Evaluation & Tracking Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dca65f4-6ba8-4867-a9c5-17f47f357e04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Functions for Performance Evaluation.\n",
    "def evaluate_performance(y_test, y_pred, dataset):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    precision = precision_score(y_test, y_pred, average='micro')\n",
    "    recall = recall_score(y_test, y_pred, average='micro')\n",
    "    \n",
    "    print(\"\\nPerformance metrics on %s set\" % dataset)    \n",
    "    print(\"Accuracy on %s set: %f\" % (dataset, accuracy))\n",
    "    print(\"F1 macro on %s set: %f\" % (dataset, f1_macro))\n",
    "    print(\"F1 micro on %s set: %f\" % (dataset, f1_micro))\n",
    "    print(\"Precision micro on %s set: %f\" % (dataset, precision))\n",
    "    print(\"Recall micro on %s set: %f\" % (dataset, recall))\n",
    "    \n",
    "    return accuracy, precision, recall, f1_micro, f1_macro\n",
    "\n",
    "\n",
    "# Function for printing Training Time & Prediction Time.\n",
    "def print_timing(training_time, prediction_time):\n",
    "    print(\"\\nTraining time: %f s\" % training_time)\n",
    "    print(\"Prediction time: %f s\" % prediction_time)\n",
    "    \n",
    "    \n",
    "# Function for Tracking the Performance Metrices.\n",
    "def track_performance_metrics(accuracy, precision, recall, f1_micro, f1_macro,\n",
    "                              accuracy_train, precision_train, recall_train, f1_micro_train, f1_macro_train,\n",
    "                              training_time, prediction_time):\n",
    "    # Logging test set performance.\n",
    "    mlflow.log_metric('accuracy', accuracy)\n",
    "    mlflow.log_metric('f1_macro', f1_macro)\n",
    "    mlflow.log_metric('f1_micro', f1_micro)\n",
    "    mlflow.log_metric('precision', precision)\n",
    "    mlflow.log_metric('recall', recall)\n",
    "\n",
    "    # Logging train set performance.\n",
    "    mlflow.log_metric('accuracy_train', accuracy_train)\n",
    "    mlflow.log_metric('f1_macro_train', f1_macro_train)\n",
    "    mlflow.log_metric('f1_micro_train', f1_micro_train)\n",
    "    mlflow.log_metric('precision_train', precision_train)\n",
    "    mlflow.log_metric('recall_train', recall_train)\n",
    "    \n",
    "    mlflow.log_metric('training_time', training_time)\n",
    "    mlflow.log_metric('prediction_time', prediction_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f376a8d-661d-495e-821b-8fbc49074add",
   "metadata": {},
   "source": [
    "<a name=\"6\"></a>\n",
    "## 6 - Experiment Creation in MLflow for Tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5f3b2b5-d815-4bef-bb2d-89631ea8ae35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Experiment Created :-\n",
      "Experiment Name : CARS24_MNIST_ASSIGNMENT\n",
      "Experiment Id   : 1\n"
     ]
    }
   ],
   "source": [
    "# Don't run this again without changing the Experiment Name.\n",
    "\n",
    "experiment_name = \"CARS24_MNIST_ASSIGNMENT\"\n",
    "run_name        = \"CARS24_MNIST_RUN\"\n",
    "experiment_id   = mlflow.create_experiment(experiment_name)\n",
    "\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:5000')\n",
    "\n",
    "print(\"New Experiment Created :-\")\n",
    "print(f\"Experiment Name : {experiment_name}\")\n",
    "print(f\"Experiment Id   : {experiment_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09af1d2-f281-4dc0-9248-42f98f1527fc",
   "metadata": {},
   "source": [
    "<a name=\"7\"></a>\n",
    "## 7 - Machine Learning Model Building :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0d865e-c3a1-417c-9a3b-12cab315de47",
   "metadata": {},
   "source": [
    "<a name=\"7.1\"></a>\n",
    "## 7.1 - Multi-class Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32faae3c-5606-425a-826f-d8a8e922eeb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('http',\n",
       " inputs: \n",
       "   [Tensor('float64', (-1, 784))]\n",
       " outputs: \n",
       "   [Tensor('uint8', (-1,))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "model_signature = infer_signature(X_train_flat, y_train)\n",
    "tracking_url_type_store , model_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61c950e9-762a-4716-bfba-615db5589ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance metrics on test set\n",
      "Accuracy on test set: 0.925800\n",
      "F1 macro on test set: 0.924792\n",
      "F1 micro on test set: 0.925800\n",
      "Precision micro on test set: 0.925800\n",
      "Recall micro on test set: 0.925800\n",
      "\n",
      "Performance metrics on train set\n",
      "Accuracy on train set: 0.935050\n",
      "F1 macro on train set: 0.934227\n",
      "F1 micro on train set: 0.935050\n",
      "Precision micro on train set: 0.935050\n",
      "Recall micro on train set: 0.935050\n",
      "\n",
      "Training time: 10.742636 s\n",
      "Prediction time: 0.012355 s\n"
     ]
    }
   ],
   "source": [
    "# Define Multi-Class Logistic Regression Model.\n",
    "logreg = LogisticRegression(random_state = 33) # default hyperparameters used.\n",
    "\n",
    "# Tracking The Experiment.\n",
    "tags        = {\"version\" : \"v1\" , \"model_name\" : \"Logistic_Rgression\"}\n",
    "description = \"Logistic Regression Model For MNIST dataset.\"\n",
    "\n",
    "with mlflow.start_run( run_name = run_name , experiment_id = experiment_id , tags = tags , description = description ):\n",
    "    \n",
    "    # Log Parameters.\n",
    "    mlflow.log_params(logreg.get_params())\n",
    "\n",
    "    # Training Model.\n",
    "    start_training = time.time()\n",
    "    logreg.fit(X_train_flat, y_train)\n",
    "    end_training = time.time()\n",
    "    \n",
    "    # Predict the Test Set.\n",
    "    start_prediction = time.time()\n",
    "    y_pred = logreg.predict(X_test_flat)\n",
    "    end_prediction = time.time()\n",
    "    \n",
    "    # Predict the Train Set.\n",
    "    y_pred_train = logreg.predict(X_train_flat)\n",
    "\n",
    "    # Evaluate Performance Metrices.\n",
    "    accuracy       , precision       , recall       , f1_micro       , f1_macro       = evaluate_performance(y_test, y_pred, 'test')\n",
    "    accuracy_train , precision_train , recall_train , f1_micro_train , f1_macro_train = evaluate_performance(y_train, y_pred_train, 'train')\n",
    "    \n",
    "    # Training & Prediction Time.\n",
    "    training_time   = end_training - start_training\n",
    "    prediction_time = end_prediction - start_prediction\n",
    "    print_timing(training_time, prediction_time)\n",
    "    \n",
    "    # Log the Model.\n",
    "    # Store all things in local folder.\n",
    "    mlflow.sklearn.log_model(sk_model = logreg, artifact_path = f\"{tags.get('model_name')}\", signature = model_signature)\n",
    "    \n",
    "    # Using Pyfunc module.\n",
    "    #mlflow.pyfunc.log_model(artifact_path = f\"{tags.get('model_name')}\" , python_model = logreg , signature = model_signature)\n",
    "    \n",
    "    # MySQL DB : Not work untill MySQL DB is not setup.\n",
    "    #mlflow.sklearn.log_model(sk_model = logreg, artifact_path = f\"{tags.get('model_name')}\", registered_model_name = \"MNIST_Model\", signature = model_signature)\n",
    "\n",
    "    # Track Performance Metrics.\n",
    "    track_performance_metrics(accuracy, precision, recall, f1_micro, f1_macro,\n",
    "                              accuracy_train, precision_train, recall_train, f1_micro_train, f1_macro_train,\n",
    "                              training_time, prediction_time)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdccde3-dc99-4361-a81c-8cb135be975f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"7.2\"></a>\n",
    "## 7.2 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f87abd1c-a9e2-44e2-828e-7441692f2b73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance metrics on test set\n",
      "Accuracy on test set: 0.968600\n",
      "F1 macro on test set: 0.968310\n",
      "F1 micro on test set: 0.968600\n",
      "Precision micro on test set: 0.968600\n",
      "Recall micro on test set: 0.968600\n",
      "\n",
      "Performance metrics on train set\n",
      "Accuracy on train set: 1.000000\n",
      "F1 macro on train set: 1.000000\n",
      "F1 micro on train set: 1.000000\n",
      "Precision micro on train set: 1.000000\n",
      "Recall micro on train set: 1.000000\n",
      "\n",
      "Training time: 31.619643 s\n",
      "Prediction time: 0.359619 s\n"
     ]
    }
   ],
   "source": [
    "# Define Random Forest Model Model.\n",
    "rfc = RandomForestClassifier(random_state= 33) # use default hyperparameters\n",
    "\n",
    "# Tracking The Experiment.\n",
    "tags        = {\"version\" : \"v1\" , \"model_name\" : \"Random_Forest\"}\n",
    "description = \"Random Forest Model For MNIST dataset.\"\n",
    "\n",
    "with mlflow.start_run( run_name = run_name , experiment_id = experiment_id , tags = tags , description = description ):\n",
    "    \n",
    "    # Log Parameters.\n",
    "    mlflow.log_params(rfc.get_params())\n",
    "    \n",
    "    # Training Model.\n",
    "    start_training = time.time()\n",
    "    rfc.fit(X_train_flat, y_train)\n",
    "    end_training = time.time()\n",
    "\n",
    "    # Predict the Test Set.\n",
    "    start_prediction = time.time()\n",
    "    y_pred = rfc.predict(X_test_flat)\n",
    "    end_prediction = time.time()\n",
    "\n",
    "    # Predict the Train Set.\n",
    "    y_pred_train = rfc.predict(X_train_flat)\n",
    "    model_signature = infer_signature(X_train_flat, y_train)\n",
    "    \n",
    "    # Evaluate Performance Metrices.\n",
    "    accuracy       , precision       , recall       , f1_micro       , f1_macro       = evaluate_performance(y_test, y_pred, 'test')\n",
    "    accuracy_train , precision_train , recall_train , f1_micro_train , f1_macro_train = evaluate_performance(y_train, y_pred_train, 'train')\n",
    "    \n",
    "    # Training & Prediction Time.\n",
    "    training_time   = end_training - start_training\n",
    "    prediction_time = end_prediction - start_prediction\n",
    "    print_timing(training_time, prediction_time)\n",
    "    \n",
    "    # Log the Model.\n",
    "    # Store all things in local folder.\n",
    "    mlflow.sklearn.log_model(sk_model = rfc, artifact_path = f\"{tags.get('model_name')}\", signature = model_signature)\n",
    "    \n",
    "    # Using Pyfunc module.\n",
    "    #mlflow.pyfunc.log_model(artifact_path = f\"{tags.get('model_name')}\" , python_model = rfc , signature = model_signature)\n",
    "    \n",
    "    # Store all things in MySQL DB : Work only when MySQL DB is setup.\n",
    "    #mlflow.sklearn.log_model(sk_model = rfc, artifact_path = f\"{tags.get('model_name')}\", registered_model_name = \"MNIST_rf_Model\", signature = model_signature)\n",
    "    \n",
    "    # Track Performance <etrics.\n",
    "    track_performance_metrics(accuracy, precision, recall, f1_micro, f1_macro,\n",
    "                              accuracy_train, precision_train, recall_train, f1_micro_train, f1_macro_train,\n",
    "                              training_time, prediction_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232d9b84-4536-4d0f-9bf7-13a4eccc09dd",
   "metadata": {},
   "source": [
    "<a name=\"7.3\"></a>\n",
    "## 7.3 - Multi Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71c32347-b0e1-47fd-b298-75f805f59596",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5513 - accuracy: 0.9386\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2670 - accuracy: 0.9701\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1998 - accuracy: 0.9769\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1633 - accuracy: 0.9809\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1408 - accuracy: 0.9835\n",
      "Model: \"Multi_Perceptron_Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (32, 384)                 301440    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (32, 256)                 98560     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (32, 10)                  2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 402,570\n",
      "Trainable params: 402,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "1875/1875 [==============================] - 2s 1ms/step\n",
      "\n",
      "Performance metrics on test set\n",
      "Accuracy on test set: 0.975900\n",
      "F1 macro on test set: 0.975582\n",
      "F1 micro on test set: 0.975900\n",
      "Precision micro on test set: 0.975900\n",
      "Recall micro on test set: 0.975900\n",
      "\n",
      "Performance metrics on train set\n",
      "Accuracy on train set: 0.986983\n",
      "F1 macro on train set: 0.986826\n",
      "F1 micro on train set: 0.986983\n",
      "Precision micro on train set: 0.986983\n",
      "Recall micro on train set: 0.986983\n",
      "\n",
      "Training time: 37.923516 s\n",
      "Prediction time: 0.498662 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\tanma\\AppData\\Local\\Temp\\tmp8znsf4st\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\tanma\\AppData\\Local\\Temp\\tmp8znsf4st\\model\\data\\model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Define Multi Layer Perceptron (MPL) Model.\n",
    "\n",
    "# We will use 1 hidden layers in this model and 384/256 units for each layers.\n",
    "# L1 regularization is applied to get faster convergence time in sparse dataset like MNIST.\n",
    "\n",
    "mlp_model = Sequential([\n",
    "                        Dense(384, activation= 'relu'               , \n",
    "                                   kernel_initializer = 'he_normal' , \n",
    "                                   kernel_regularizer = keras.regularizers.l1(0.00001)\n",
    "                              ),\n",
    "                        Dense(256, activation= 'relu'               , \n",
    "                                   kernel_initializer = 'he_normal' , \n",
    "                                   kernel_regularizer = keras.regularizers.l1(0.0001)\n",
    "                              ),\n",
    "                        Dense(10)\n",
    "                       ] , \n",
    "                       name = \"Multi_Perceptron_Model\"\n",
    "                      )\n",
    "\n",
    "# Compile model.\n",
    "mlp_model.compile(optimizer = 'adam',\n",
    "                  loss      = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics   = ['accuracy'])\n",
    "\n",
    "\n",
    "# Tracking The Experiment.\n",
    "tags        = {\"version\" : \"v1\" , \"model_name\" : \"Multi_Layer_Perceptron\"}\n",
    "description = \"Multi Layer Perceptron Model For MNIST dataset.\"\n",
    "model_config = {\n",
    "                    \"layers\": [\n",
    "                        {\"type\": \"Dense\", \"units\": 384, \"activation\": \"relu\", \"kernel_initializer\": \"he_normal\", \"kernel_regularizer\": \"l1\", \"kernel_regularizer_param\": 0.00001},\n",
    "                        {\"type\": \"Dense\", \"units\": 256, \"activation\": \"relu\", \"kernel_initializer\": \"he_normal\", \"kernel_regularizer\": \"l1\", \"kernel_regularizer_param\": 0.0001},\n",
    "                        {\"type\": \"Dense\", \"units\": 10}\n",
    "                    ],\n",
    "                    \"compile\": {\"optimizer\": \"adam\", \"loss\": \"SparseCategoricalCrossentropy\", \"loss_args\": {\"from_logits\": True}, \"metrics\": [\"accuracy\"]}\n",
    "                }\n",
    "\n",
    "\n",
    "with mlflow.start_run( run_name = run_name , experiment_id = experiment_id , tags = tags , description = description ):\n",
    "    \n",
    "    # Log Parameters.\n",
    "    mlflow.log_params(model_config)  # mlp_model.get_config()\n",
    "\n",
    "    # Training Model.\n",
    "    start_training = time.time()\n",
    "    mlp_model.fit(X_train_flat, y_train, epochs=5)\n",
    "    mlp_model.summary()\n",
    "    end_training   = time.time()\n",
    "\n",
    "    # Predict the Test Set.\n",
    "    start_prediction = time.time()\n",
    "    y_pred_long      = mlp_model.predict(X_test_flat)\n",
    "    y_pred           = np.argmax(y_pred_long, axis=1)\n",
    "    end_prediction   = time.time()\n",
    "\n",
    "    # Predict the Train Set.\n",
    "    y_pred_train_long = mlp_model.predict(X_train_flat)\n",
    "    y_pred_train      = np.argmax(y_pred_train_long, axis=1)\n",
    "\n",
    "    model_signature = infer_signature(X_train_flat, y_train)\n",
    "    \n",
    "    # Evaluate Performance Metrices.\n",
    "    accuracy       , precision       , recall       , f1_micro       , f1_macro       = evaluate_performance(y_test  , y_pred       , 'test')\n",
    "    accuracy_train , precision_train , recall_train , f1_micro_train , f1_macro_train = evaluate_performance(y_train , y_pred_train , 'train')\n",
    "    \n",
    "    # Training & Prediction Time.\n",
    "    training_time   = end_training   - start_training\n",
    "    prediction_time = end_prediction - start_prediction\n",
    "    print_timing(training_time, prediction_time)\n",
    "    \n",
    "    # Log the Model.\n",
    "    mlflow.keras.log_model(keras_model = mlp_model , artifact_path = f\"{tags.get('model_name')}\", signature = model_signature)\n",
    "    \n",
    "    #mlflow.keras.save_model(model = mlp_model , path = f\"{tags.get('model_name')}\", mlflow_model = \"MNIST_mlp_Model\")\n",
    "    \n",
    "    # Using Pyfunc module.\n",
    "    #mlflow.pyfunc.log_model(artifact_path = f\"{tags.get('model_name')}\" , python_model = mlp_model , signature = model_signature)\n",
    "    \n",
    "    \n",
    "    # Track Performance Metrics.\n",
    "    track_performance_metrics(accuracy, precision, recall, f1_micro, f1_macro,\n",
    "                              accuracy_train, precision_train, recall_train, f1_micro_train, f1_macro_train,\n",
    "                              training_time, prediction_time)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47efca66-864f-4469-a2b6-4c583ab5ad95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dir(mlflow.tensorflow.pyfunc())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7e2213-d740-4d20-8cf3-8907c0ff0d92",
   "metadata": {},
   "source": [
    "<a name=\"7.4\"></a>\n",
    "## 7.4 - Convolutional Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0f21954-8a14-4b34-8172-665c71815915",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 22s 11ms/step - loss: 0.1124 - accuracy: 0.9651\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0418 - accuracy: 0.9873\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0296 - accuracy: 0.9902\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0218 - accuracy: 0.9932\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0175 - accuracy: 0.9945\n",
      "Model: \"Convolutional_Neural_Network_Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 16)        160       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 8, 8, 16)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 6, 16)          2320      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               147712    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 155,082\n",
      "Trainable params: 155,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "1875/1875 [==============================] - 6s 3ms/step\n",
      "\n",
      "Performance metrics on test set\n",
      "Accuracy on test set: 0.990900\n",
      "F1 macro on test set: 0.990800\n",
      "F1 micro on test set: 0.990900\n",
      "Precision micro on test set: 0.990900\n",
      "Recall micro on test set: 0.990900\n",
      "\n",
      "Performance metrics on train set\n",
      "Accuracy on train set: 0.996667\n",
      "F1 macro on train set: 0.996647\n",
      "F1 micro on train set: 0.996667\n",
      "Precision micro on train set: 0.996667\n",
      "Recall micro on train set: 0.996667\n",
      "\n",
      "Training time: 107.135191 s\n",
      "Prediction time: 1.068087 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\tanma\\AppData\\Local\\Temp\\tmpti4qs44z\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\tanma\\AppData\\Local\\Temp\\tmpti4qs44z\\model\\data\\model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Define Convolutional Neural Network Model.\n",
    "\n",
    "# The model is constructed by several Dense layers\n",
    "# We use relu activation and he initializer to get faster converge time\n",
    "# The first layer is convolutional layer with 16 filter, 3x3 kernel size, 1 stride\n",
    "# The second layer is the same with the first layer. They are supposed to capture feature maps from digit image.\n",
    "# The third layer is pooling with maximum aggregation. It is used to reduce the size of feature maps.\n",
    "# The fourth layer is convolutional layer for the result from maximum pooling.\n",
    "# The next layer is dense neural network with 256 units, before feeding this layer with data,\n",
    "# we need to flatten first the data\n",
    "# The last layer / output layer is dense neural network with 10 units (the same with number of class)\n",
    "\n",
    "cnn_model = Sequential(\n",
    "                            [               \n",
    "                             Conv2D(16, kernel_size        = (3, 3), \n",
    "                                        activation         = 'relu', \n",
    "                                        input_shape        = (28,28,1), # shape 28x28x1\n",
    "                                        kernel_initializer = 'he_normal'\n",
    "                                   ),\n",
    "                             Conv2D(16, kernel_size        = (3, 3), \n",
    "                                       activation          = 'relu', \n",
    "                                       kernel_initializer  = 'he_normal'\n",
    "                                  ),\n",
    "                             MaxPooling2D(pool_size=(3, 3)),\n",
    "                             Conv2D(16, kernel_size        = (3, 3), \n",
    "                                       activation          = 'relu', \n",
    "                                       kernel_initializer  = 'he_normal'\n",
    "                                   ),\n",
    "                             Flatten(),\n",
    "                             Dense(256, activation         = 'relu', \n",
    "                                        kernel_initializer = 'he_normal'\n",
    "                                  ),\n",
    "                             Dense(10, activation          = 'softmax')\n",
    "                            ] ,  name = \"Convolutional_Neural_Network_Model\" \n",
    "                     )\n",
    "\n",
    "# Compile model\n",
    "cnn_model.compile(optimizer       = 'adam',\n",
    "                        loss      = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                        metrics   = ['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Tracking The Experiment.\n",
    "tags        = {\"version\" : \"v1\" , \"model_name\" : \"Convolutional_Neural_Network\"}\n",
    "description = \"Convolutional Neural Network Model For MNIST dataset.\"\n",
    "model_config = {\n",
    "                    \"layers\": [\n",
    "                        {\"type\": \"Conv2D\"      , \"kernel_size\": (3, 3), \"actv\": \"relu\", \"kernel_initializer\": \"he_normal\"},\n",
    "                        {\"type\": \"Conv2D\"      , \"kernel_size\": (3, 3), \"actv\": \"relu\", \"kernel_initializer\": \"he_normal\"},\n",
    "                        {\"type\": \"MaxPooling2D\", \"pool_size\": (3, 3)},\n",
    "                        {\"type\": \"Conv2D\"      , \"kernel_size\": (3, 3), \"actv\": \"relu\", \"kernel_initializer\": \"he_normal\"},\n",
    "                        {\"type\": \"Flatten\"}    ,\n",
    "                        {\"type\": \"Dense\"       , \"units\": 256, \"actv\": \"relu\", \"kernel_initializer\": \"he_normal\"},\n",
    "                        {\"type\": \"Dense\"       , \"units\": 10 , \"actv\": \"softmax\"}\n",
    "                    ],\n",
    "                    \"compile\": {\"optimizer\": \"adam\", \"loss\": \"SparseCategoricalCrossentropy\", \"loss_args\": {\"from_logits\": True}, \"metrics\": [\"accuracy\"]}\n",
    "                }\n",
    "\n",
    "\n",
    "with mlflow.start_run( run_name = run_name , experiment_id = experiment_id , tags = tags , description = description ):\n",
    "    \n",
    "    # Log Parameters.\n",
    "    mlflow.log_params(model_config)\n",
    "\n",
    "    # Training Model\n",
    "    start_training = time.time()\n",
    "    cnn_model.fit(X_train, y_train, epochs=5)\n",
    "    cnn_model.summary()\n",
    "    end_training   = time.time()\n",
    "\n",
    "    # Predict the Test Set\n",
    "    start_prediction = time.time()\n",
    "    y_pred_long      = cnn_model.predict(X_test)\n",
    "    y_pred           = np.argmax(y_pred_long, axis=1)\n",
    "    end_prediction   = time.time()\n",
    "\n",
    "    # Predict the Train Set\n",
    "    y_pred_train_long = cnn_model.predict(X_train)\n",
    "    y_pred_train      = np.argmax(y_pred_train_long, axis=1)\n",
    "\n",
    "    # Evaluate Performance Metrices.\n",
    "    accuracy       , precision       , recall       , f1_micro       , f1_macro       = evaluate_performance( y_test  , y_pred       , 'test')\n",
    "    accuracy_train , precision_train , recall_train , f1_micro_train , f1_macro_train = evaluate_performance( y_train , y_pred_train , 'train')\n",
    "    \n",
    "    # Training & Prediction Time.                                                                                                    \n",
    "    training_time   = end_training   - start_training\n",
    "    prediction_time = end_prediction - start_prediction\n",
    "    print_timing(training_time, prediction_time)\n",
    "    \n",
    "    model_signature = infer_signature(X_train_flat, y_train)\n",
    "    \n",
    "    # Log the Model.\n",
    "    mlflow.keras.log_model(keras_model = cnn_model , artifact_path = f\"{tags.get('model_name')}\", signature = model_signature)\n",
    "    \n",
    "    #mlflow.keras.log_model(keras_model = cnn_model , artifact_path = f\"{tags.get('model_name')}\", registered_model_name = \"MNIST_cnn_Model\", signature = model_signature)\n",
    "    \n",
    "    # Track Performance Metrics.\n",
    "    track_performance_metrics(accuracy, precision, recall, f1_micro, f1_macro,\n",
    "                              accuracy_train, precision_train, recall_train, f1_micro_train, f1_macro_train,\n",
    "                              training_time, prediction_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6271ffc-a73b-45fd-b2d5-651351d29ceb",
   "metadata": {},
   "source": [
    "<a name=\"\"></a>\n",
    "## 8 - Run MLflow tracking UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bb7cab6-744a-464d-b6f7-8fd5fb092856",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !mlflow ui  # If this will not work in notebook then Open CMD & type command -> mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af9fd67-353a-40f2-abdf-92a95eb5b2ff",
   "metadata": {},
   "source": [
    "<a name=\"9\"></a>\n",
    "## 9 - Get The Best Model Based on Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f09665a-d6fb-403c-9883-959cb5c5552d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment : CARS24_MNIST_ASSIGNMENT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>status</th>\n",
       "      <th>artifact_uri</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>metrics.prediction_time</th>\n",
       "      <th>metrics.accuracy_train</th>\n",
       "      <th>metrics.recall_train</th>\n",
       "      <th>metrics.f1_macro_train</th>\n",
       "      <th>...</th>\n",
       "      <th>params.penalty</th>\n",
       "      <th>params.C</th>\n",
       "      <th>tags.mlflow.source.type</th>\n",
       "      <th>tags.mlflow.note.content</th>\n",
       "      <th>tags.model_name</th>\n",
       "      <th>tags.mlflow.runName</th>\n",
       "      <th>tags.mlflow.log-model.history</th>\n",
       "      <th>tags.version</th>\n",
       "      <th>tags.mlflow.source.name</th>\n",
       "      <th>tags.mlflow.user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8a86c69f28b04545a1d54b773fb7eaab</td>\n",
       "      <td>1</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>./mlruns/1/8a86c69f28b04545a1d54b773fb7eaab/ar...</td>\n",
       "      <td>2024-03-31 07:39:20.663000+00:00</td>\n",
       "      <td>2024-03-31 07:41:19.824000+00:00</td>\n",
       "      <td>1.068087</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.996647</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>Convolutional Neural Network Model For MNIST d...</td>\n",
       "      <td>Convolutional_Neural_Network</td>\n",
       "      <td>CARS24_MNIST_RUN</td>\n",
       "      <td>[{\"run_id\": \"8a86c69f28b04545a1d54b773fb7eaab\"...</td>\n",
       "      <td>v1</td>\n",
       "      <td>c:\\Users\\tanma\\anaconda3\\envs\\CARS24\\lib\\site-...</td>\n",
       "      <td>tanma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e1e841ac1ad1475abe98c0e3b1894906</td>\n",
       "      <td>1</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>./mlruns/1/e1e841ac1ad1475abe98c0e3b1894906/ar...</td>\n",
       "      <td>2024-03-31 07:38:33.978000+00:00</td>\n",
       "      <td>2024-03-31 07:39:20.551000+00:00</td>\n",
       "      <td>0.498662</td>\n",
       "      <td>0.986983</td>\n",
       "      <td>0.986983</td>\n",
       "      <td>0.986826</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>Multi Layer Perceptron Model For MNIST dataset.</td>\n",
       "      <td>Multi_Layer_Perceptron</td>\n",
       "      <td>CARS24_MNIST_RUN</td>\n",
       "      <td>[{\"run_id\": \"e1e841ac1ad1475abe98c0e3b1894906\"...</td>\n",
       "      <td>v1</td>\n",
       "      <td>c:\\Users\\tanma\\anaconda3\\envs\\CARS24\\lib\\site-...</td>\n",
       "      <td>tanma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7f076721f90242b6ba89cd64f17b086e</td>\n",
       "      <td>1</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>./mlruns/1/7f076721f90242b6ba89cd64f17b086e/ar...</td>\n",
       "      <td>2024-03-31 07:37:49.694000+00:00</td>\n",
       "      <td>2024-03-31 07:38:26.219000+00:00</td>\n",
       "      <td>0.359619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>Random Forest Model For MNIST dataset.</td>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>CARS24_MNIST_RUN</td>\n",
       "      <td>[{\"run_id\": \"7f076721f90242b6ba89cd64f17b086e\"...</td>\n",
       "      <td>v1</td>\n",
       "      <td>c:\\Users\\tanma\\anaconda3\\envs\\CARS24\\lib\\site-...</td>\n",
       "      <td>tanma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f16fdf4feae1435fae1aebb97c43f711</td>\n",
       "      <td>1</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>./mlruns/1/f16fdf4feae1435fae1aebb97c43f711/ar...</td>\n",
       "      <td>2024-03-31 07:37:29.751000+00:00</td>\n",
       "      <td>2024-03-31 07:37:43.547000+00:00</td>\n",
       "      <td>0.012355</td>\n",
       "      <td>0.935050</td>\n",
       "      <td>0.935050</td>\n",
       "      <td>0.934227</td>\n",
       "      <td>...</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>Logistic Regression Model For MNIST dataset.</td>\n",
       "      <td>Logistic_Rgression</td>\n",
       "      <td>CARS24_MNIST_RUN</td>\n",
       "      <td>[{\"run_id\": \"f16fdf4feae1435fae1aebb97c43f711\"...</td>\n",
       "      <td>v1</td>\n",
       "      <td>c:\\Users\\tanma\\anaconda3\\envs\\CARS24\\lib\\site-...</td>\n",
       "      <td>tanma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id experiment_id    status  \\\n",
       "0  8a86c69f28b04545a1d54b773fb7eaab             1  FINISHED   \n",
       "1  e1e841ac1ad1475abe98c0e3b1894906             1  FINISHED   \n",
       "2  7f076721f90242b6ba89cd64f17b086e             1  FINISHED   \n",
       "3  f16fdf4feae1435fae1aebb97c43f711             1  FINISHED   \n",
       "\n",
       "                                        artifact_uri  \\\n",
       "0  ./mlruns/1/8a86c69f28b04545a1d54b773fb7eaab/ar...   \n",
       "1  ./mlruns/1/e1e841ac1ad1475abe98c0e3b1894906/ar...   \n",
       "2  ./mlruns/1/7f076721f90242b6ba89cd64f17b086e/ar...   \n",
       "3  ./mlruns/1/f16fdf4feae1435fae1aebb97c43f711/ar...   \n",
       "\n",
       "                        start_time                         end_time  \\\n",
       "0 2024-03-31 07:39:20.663000+00:00 2024-03-31 07:41:19.824000+00:00   \n",
       "1 2024-03-31 07:38:33.978000+00:00 2024-03-31 07:39:20.551000+00:00   \n",
       "2 2024-03-31 07:37:49.694000+00:00 2024-03-31 07:38:26.219000+00:00   \n",
       "3 2024-03-31 07:37:29.751000+00:00 2024-03-31 07:37:43.547000+00:00   \n",
       "\n",
       "   metrics.prediction_time  metrics.accuracy_train  metrics.recall_train  \\\n",
       "0                 1.068087                0.996667              0.996667   \n",
       "1                 0.498662                0.986983              0.986983   \n",
       "2                 0.359619                1.000000              1.000000   \n",
       "3                 0.012355                0.935050              0.935050   \n",
       "\n",
       "   metrics.f1_macro_train  ...  params.penalty  params.C  \\\n",
       "0                0.996647  ...            None      None   \n",
       "1                0.986826  ...            None      None   \n",
       "2                1.000000  ...            None      None   \n",
       "3                0.934227  ...              l2       1.0   \n",
       "\n",
       "   tags.mlflow.source.type                           tags.mlflow.note.content  \\\n",
       "0                    LOCAL  Convolutional Neural Network Model For MNIST d...   \n",
       "1                    LOCAL    Multi Layer Perceptron Model For MNIST dataset.   \n",
       "2                    LOCAL             Random Forest Model For MNIST dataset.   \n",
       "3                    LOCAL       Logistic Regression Model For MNIST dataset.   \n",
       "\n",
       "                tags.model_name  tags.mlflow.runName  \\\n",
       "0  Convolutional_Neural_Network     CARS24_MNIST_RUN   \n",
       "1        Multi_Layer_Perceptron     CARS24_MNIST_RUN   \n",
       "2                 Random_Forest     CARS24_MNIST_RUN   \n",
       "3            Logistic_Rgression     CARS24_MNIST_RUN   \n",
       "\n",
       "                       tags.mlflow.log-model.history  tags.version  \\\n",
       "0  [{\"run_id\": \"8a86c69f28b04545a1d54b773fb7eaab\"...            v1   \n",
       "1  [{\"run_id\": \"e1e841ac1ad1475abe98c0e3b1894906\"...            v1   \n",
       "2  [{\"run_id\": \"7f076721f90242b6ba89cd64f17b086e\"...            v1   \n",
       "3  [{\"run_id\": \"f16fdf4feae1435fae1aebb97c43f711\"...            v1   \n",
       "\n",
       "                             tags.mlflow.source.name tags.mlflow.user  \n",
       "0  c:\\Users\\tanma\\anaconda3\\envs\\CARS24\\lib\\site-...            tanma  \n",
       "1  c:\\Users\\tanma\\anaconda3\\envs\\CARS24\\lib\\site-...            tanma  \n",
       "2  c:\\Users\\tanma\\anaconda3\\envs\\CARS24\\lib\\site-...            tanma  \n",
       "3  c:\\Users\\tanma\\anaconda3\\envs\\CARS24\\lib\\site-...            tanma  \n",
       "\n",
       "[4 rows x 56 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the tracking URI to the MLflow server.\n",
    "#mlflow.set_tracking_uri('http://127.0.0.1:5000')\n",
    "\n",
    "#experiment_name = \"CARS24_MNIST_ASSIGNMENT\"  # Already defined in starting.\n",
    "metric_name     = 'accuracy' \n",
    "experiment      = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "print(f\"Experiment : {experiment_name}\")\n",
    "\n",
    "all_model_info = mlflow.search_runs(experiment_ids = [experiment.experiment_id] , order_by = [f\"metrics.{metric_name} DESC\"], max_results=5)\n",
    "all_model_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3e8d91b-2022-4b17-b1aa-70e63f6491d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_model_info.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f125ccf-65e3-49e2-a7b6-2c442a23e7d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Details : \n",
      "       Experiment Id   : 1 , \n",
      "       Run Id          : 3be588a1643d4c9bb0389a63ffa504bd , \n",
      "       Artifact URI    : ./mlruns/1/3be588a1643d4c9bb0389a63ffa504bd/artifacts , \n",
      "       Model Name      : Convolutional_Neural_Network , \n",
      "       Accuracy        : 98.19 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Model Details : \\n \\\n",
    "      Experiment Id   : {all_model_info.iloc[0]['experiment_id']} , \\n \\\n",
    "      Run Id          : {all_model_info.iloc[0]['run_id']} , \\n \\\n",
    "      Artifact URI    : {all_model_info.iloc[0]['artifact_uri']} , \\n \\\n",
    "      Model Name      : {all_model_info.iloc[0]['tags.model_name']} , \\n \\\n",
    "      Accuracy        : {round(all_model_info.iloc[0]['metrics.accuracy'] * 100 , 2)} %\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa32ea4-0c4d-4556-8920-95be16d6a46d",
   "metadata": {},
   "source": [
    "<a name=\"10\"></a>\n",
    "## 10 - Inferencing Using 1st Image of Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48f5596d-1a88-4e8c-9d1b-faa9550a7391",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1fb89400688>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the best model for prediction or further evaluation.\n",
    "best_model_run_id = all_model_info.iloc[0].run_id\n",
    "best_model_name   = all_model_info.iloc[0]['tags.model_name']\n",
    "\n",
    "# Load the best model.\n",
    "best_model = mlflow.keras.load_model(\"runs:/\" + best_model_run_id + f\"/{best_model_name}\")\n",
    "#best_model = mlflow.pyfunc.load_model(\"runs:/\" + best_model_run_id + f\"/{best_model_name}\")\n",
    "#best_model = mlflow.pyfunc.load_model(\"runs:/\" + \"130c9db5e2fd45c4af2daf72c43fafb7\" +\"/Random_Forest\")\n",
    "\n",
    "best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3c24ac0-793d-46ef-b25d-fc409fcc3a7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 1st training example : (28, 28, 1)\n",
      "Original Label : 5\n",
      "Model input image shape : (1, 28, 28, 1)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Predicted Label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inferencing with 1st Image of dataset.\n",
    "n = 0\n",
    "\n",
    "print(f\"Shape of 1st training example : {X_train[n,:].shape}\")\n",
    "print(\"Original Label : %s\" % (y_train[n]))\n",
    "plt.imshow(X_train[n,:], interpolation='nearest')\n",
    "\n",
    "model_input_img = np.expand_dims( X_train[n], axis=0 )           # For Neural Network.\n",
    "#model_input_img = model_input_img = np.reshape(X_train[n], (-1, 784))\n",
    "#model_input_img = np.reshape(X_train[n], (-1, 28, 28, 1))\n",
    "\n",
    "\n",
    "#model_input_img = X_train[n].reshape(-1, 28*28)                 # For Random Forest.\n",
    "print(f\"Model input image shape : {model_input_img.shape}\")\n",
    "\n",
    "prediction = np.argmax( best_model.predict(model_input_img) )    # For Neural Network.\n",
    "#prediction = best_model.predict( model_input_img)               # For Random Forest.\n",
    "print(\"Predicted Label: %s\" % (prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6f8d67",
   "metadata": {},
   "source": [
    "<a name=\"11\"></a>\n",
    "## 11 - Save the best model i.e. Neural Network Model into a folder Best_Model for Inference & Deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eef52685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully at: Best_Model\\model.h5\n"
     ]
    }
   ],
   "source": [
    "# Create a directory to save the model\n",
    "save_path = \"Best_Model\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "best_model.save(os.path.join(save_path, \"model.h5\"))\n",
    "\n",
    "# Verify that the model is saved\n",
    "saved_model_path = os.path.join(save_path, \"model.h5\")\n",
    "if os.path.exists(saved_model_path):\n",
    "    print(\"Model saved successfully at:\", saved_model_path)\n",
    "else:\n",
    "    print(\"Failed to save the model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "862632d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 1st training example : (28, 28, 1)\n",
      "Original Label : 4\n",
      "Model input image shape : (1, 28, 28, 1)\n",
      "WARNING:tensorflow:5 out of the last 2194 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001FB88B5F4C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 2194 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001FB88B5F4C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "Predicted Label: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the saved model\n",
    "loaded_model = load_model(\"Best_Model/model.h5\")\n",
    "\n",
    "# Inferencing with 1st Image of dataset.\n",
    "n = 2\n",
    "\n",
    "print(f\"Shape of 1st training example : {X_train[n,:].shape}\")\n",
    "print(\"Original Label : %s\" % (y_train[n]))\n",
    "plt.imshow(X_train[n,:], interpolation='nearest')\n",
    "\n",
    "\n",
    "print(f\"Model input image shape : {model_input_img.shape}\")\n",
    "model_input_img = np.expand_dims( X_train[n], axis=0 )\n",
    "\n",
    "# Make a prediction\n",
    "prediction = np.argmax( loaded_model.predict(model_input_img) )    # For Neural Network.\n",
    "print(\"Predicted Label: %s\" % (prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef0738d",
   "metadata": {},
   "source": [
    "<a name=\"12\"></a>\n",
    "## 12 - Save the image for inference purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67d3824b-bc7e-4dc6-850b-06c0b44ce76e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved successfully at: inference_images\\2.png\n",
      "Image shape: (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Saving Image for inference purpose.\n",
    "\n",
    "# Create a directory to save the images\n",
    "save_path = \"inference_images\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# Inferencing with 1st Image of dataset.\n",
    "#n = 2\n",
    "\n",
    "# Display the image as grayscale\n",
    "plt.imshow(X_train[n, :], cmap='gray', interpolation='nearest')\n",
    "\n",
    "# Save the image\n",
    "image_path = os.path.join(save_path, f\"{n}.png\")\n",
    "plt.savefig(image_path, cmap='gray')  # Save as grayscale\n",
    "\n",
    "print(\"Image saved successfully at:\", image_path)\n",
    "print(f\"Image shape: {X_train[n, :, :, 0].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e57299a-6d20-4b46-b2ca-8a9e29b5716a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (480, 640, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the saved image.\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Path to the saved image\n",
    "image_path = f\"{save_path}/{n}.png\"\n",
    "\n",
    "# Read the image\n",
    "image = mpimg.imread(image_path)\n",
    "\n",
    "# Display the image shape\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "\n",
    "# Show the image\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # Turn off axis numbers\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f079779-5e09-4d34-920d-39abaf1f520c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec225eb-359f-4af5-8a29-f8bccd1a8a20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
